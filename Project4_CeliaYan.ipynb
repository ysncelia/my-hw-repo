{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4\n",
    "\n",
    "In this project, you will summarize and present your analysis from Projects 1-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Intro: Problem Statement/ Specific Aim for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the relationship between being admitted to graduate school and three factors - GRE score, GPA score and undergraduate school prestige and analyze how each factor would influence on graduate school admission decision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Dataset:  Description of data and Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Description of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this UCLA admission dataset, there are four variables - admit, GRE, GPA and Prestige. Each variable is described as below. The variable \"Admit\" is considered as response variable; other three variables are considered as predictors. As shown as below, there are 400 data points with two missing values in GRE, two missing values in GPA and one missing values in Prestige. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable | Description | Type of Variable\n",
    "---| ---| ---\n",
    "Admit | 0 = not admitted 1 = admitted | categorical\n",
    "GRE| score 200-800 | continuous \n",
    "GPA| score 0.0-4.0 | continuous \n",
    "Prestige| 4=no prestige, 3=low prestige, 2=good prestige, 1=high prestige | categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            admit         gre        gpa    prestige\n",
      "count  400.000000  398.000000  398.00000  399.000000\n",
      "mean     0.317500  588.040201    3.39093    2.486216\n",
      "std      0.466087  115.628513    0.38063    0.945333\n",
      "min      0.000000  220.000000    2.26000    1.000000\n",
      "25%      0.000000  520.000000    3.13000    2.000000\n",
      "50%      0.000000  580.000000    3.39500    2.000000\n",
      "75%      1.000000  660.000000    3.67000    3.000000\n",
      "max      1.000000  800.000000    4.00000    4.000000\n",
      "admit       0\n",
      "gre         2\n",
      "gpa         2\n",
      "prestige    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"../assets/admissions.csv\")\n",
    "print(data.describe())\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocesing focuses on testing and dealing with 1) Missing Values; 2) collinearity; 3) Data outliers and scales; 4) Dumifying categorical predictor - undergraduate school prestige"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to clean missing value of Prestige\n",
    "\n",
    "I filled valued into data-missing observations for three factors respectively. Since prestige variable is categorical one, I checked average gre and gpa level for each prestige and filled prestige level value into the missing record by comparing gpa level with the average level. In this dataset, the prestige missing record has the gre score 660 which is much higher than the average gre score falling into prestige 1 of the rest records. So prestige 1 is assigned to this missing record. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     admit    gre  gpa  prestige\n",
      "236      1  660.0  NaN       NaN\n",
      "                 gre       gpa\n",
      "prestige                      \n",
      "1.0       611.803279  3.453115\n",
      "2.0       596.621622  3.364027\n",
      "3.0       574.876033  3.432893\n",
      "4.0       570.149254  3.318358\n"
     ]
    }
   ],
   "source": [
    "print(data[data['prestige'].isnull()])\n",
    "print(data.groupby('prestige')['gre','gpa'].mean())\n",
    "data_fill = data.copy()\n",
    "data_fill[\"prestige\"].fillna(1.0, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to clean missing values of GRE and GPA\n",
    "Since GRE and GPA are continuous variables, the missing observations are filled with average scores of non-missing records grouped by each prestige."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       0\n",
       "gre         0\n",
       "gpa         0\n",
       "prestige    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fill[\"gre\"].fillna(data_fill.groupby('prestige')['gre'].transform('mean'), inplace=True)\n",
    "data_fill[\"gpa\"].fillna(data_fill.groupby('prestige')['gpa'].transform('mean'), inplace=True)\n",
    "data_fill.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to test collinearity\n",
    "From the plot below, we can see that correlation among predictors is low and no collinearity exists. \n",
    "\n",
    "(??? I'm not sure why the correlation heatmap shows low correlation among all predictors (all black colors) in the beginning but when I reran the code the heatmap shows gre and gpa correlate at some level (red color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD8CAYAAADUv3dIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/X+wVKBQX5bEDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108a89b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "f=sns.heatmap(data_fill[['gre','gpa','prestige']].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to rescale data\n",
    "Both of GPA and GRE scores have marginal outliers. Also, GRE score has a much larger magnitude of scale than GPA score  and it might dominate the objective function and make the estimator unable to learn from other features correctly as expected. To scaling the entire sample and shrinking the distance between outliers and inliers, I will use QuantileTransformer to scale the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>prestige</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.761948</td>\n",
       "      <td>0.523537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.592444</td>\n",
       "      <td>0.684763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.430727</td>\n",
       "      <td>-0.493553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.599937</td>\n",
       "      <td>-1.161976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  prestige       gre       gpa\n",
       "0      0       3.0 -1.761948  0.523537\n",
       "1      1       3.0  0.592444  0.684763\n",
       "2      1       1.0  5.199338  5.199338\n",
       "3      1       4.0  0.430727 -0.493553\n",
       "4      0       4.0 -0.599937 -1.161976"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "X_scores = data_fill[['gre','gpa']]\n",
    "X_scale =QuantileTransformer(output_distribution='normal').fit_transform(X_scores)\n",
    "X_scale = pd.DataFrame(X_scale, columns=['gre','gpa'])\n",
    "data_new=data_fill[['admit','prestige']].join(X_scale.loc[:,:])\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to dummify categorical predictor - prestige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>prestige</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.761948</td>\n",
       "      <td>0.523537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.592444</td>\n",
       "      <td>0.684763</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.430727</td>\n",
       "      <td>-0.493553</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.599937</td>\n",
       "      <td>-1.161976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  prestige       gre       gpa  prestige_1.0  prestige_2.0  \\\n",
       "0      0       3.0 -1.761948  0.523537             0             0   \n",
       "1      1       3.0  0.592444  0.684763             0             0   \n",
       "2      1       1.0  5.199338  5.199338             1             0   \n",
       "3      1       4.0  0.430727 -0.493553             0             0   \n",
       "4      0       4.0 -0.599937 -1.161976             0             0   \n",
       "\n",
       "   prestige_3.0  prestige_4.0  \n",
       "0             1             0  \n",
       "1             1             0  \n",
       "2             0             0  \n",
       "3             0             1  \n",
       "4             0             1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(data_new['prestige'], prefix='prestige')\n",
    "df = data_new.join(dummies.loc[:,:])\n",
    "features = ['gre','gpa']+list(dummies.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When modeling the class variables - prestige, I dropped prestige_1.0 because it can be determined by another three. Removing one class variable among total four class variables can avoid multicollinearity. The removed variable can be the base category against which other categories can be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Part 3 - Demo: Provide a table that explains the data by admission status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gre</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.035965</td>\n",
       "      <td>0.539418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.506576</td>\n",
       "      <td>1.642140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gpa</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.050610</td>\n",
       "      <td>0.594793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.527127</td>\n",
       "      <td>1.760732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>sum</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>sum</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>sum</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_4.0</th>\n",
       "      <th>sum</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "admit                      0          1\n",
       "gre          mean   0.035965   0.539418\n",
       "             std    1.506576   1.642140\n",
       "gpa          mean   0.050610   0.594793\n",
       "             std    1.527127   1.760732\n",
       "prestige_1.0 sum   28.000000  34.000000\n",
       "prestige_2.0 sum   97.000000  53.000000\n",
       "prestige_3.0 sum   93.000000  28.000000\n",
       "prestige_4.0 sum   55.000000  12.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[features].groupby(df['admit']).agg({'gre':['mean','std'],'gpa':['mean','std'],'prestige_1.0': ['sum'],\n",
    "                                       'prestige_2.0': ['sum'],'prestige_3.0': ['sum'],'prestige_4.0': ['sum']}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency for each prestige by admission status:\n",
    "\n",
    "| Not Admitted | Admitted\n",
    "---| ---|---\n",
    "Prestige 1 | 45 (%) | 54 (%)\n",
    "Prestige 2 | 64 (%) | 35 (%)\n",
    "Prestige 3 | 77 (%) | 23 (%)\n",
    "Prestige 4 | 82 (%) | 18 (%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4-  Methods: Write up the methods used in your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Logistic Regression as main model is applied to get probabilities and odds of being admitted to graduate school for each factor holding other factors constant. To evaluate the classifier, a new dataset is created with logical combinations of input values to see how the predicted probability of admission changes across different predictors.\n",
    "Statsmodel and sklearn modules are both applied to compare results. \n",
    "\n",
    "2) Another three Classifier models (K-nearest neighbors, Random Forests and AdaBoost) are applied to compare predict results and evaluate modeling qualities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 - Results: Write up your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) From the results of the Logistic Regression model, GPA score with one unit increase is expected to increase 16% of the odds of being admitted to the graduate school holding other variables constant; GRE score with one unit increase is expected to increase 12% of the odds. However these results are not seen statistically significant with low p values. From the below probability plots, it is seen that the influence of GPA scores and GRE scores on the odds of admission to graduate school is affected by different prestige of undergraduate schools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image1-result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image2-odds.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) The class variable - Prestige is seen to have a statistically significant influence on the probability of being admitted to graduate school. The odds of being admitted decline as the college rank decreases from tier 1 to tier 4 holding gre and gpa constant. When we use the created and enumberated dataset to predict admission probabilities, as below as seen, with the same gre and gpa score, the probability of being admitted is the highest for students who attended tier 1 college and declines as the college ranks goes down to tier 4. \n",
    "\n",
    "When comparing stats model and sklearn, the model coefficients and odds are the same. But the predicted probabilities of admission on the same enumberated dataset are slightly different. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Results from statsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image3-predictstats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Results from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image3-predictsk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) The predict results support our initial hypothesis. However, the prediction power looks not strong. The accuracy rate is only 68% close to baseline. Precision and recall rates are both low. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image5-scoresk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) To try to increase prediction power, another three models are tested but the accuracy scores keep the level of 65%-69%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K-nearest neighbors: \n",
    "After splitting the dataset into training set, cross-validation set and test set, k is optimized as parameter into K-neighbors Classifier. The cross validation score is 65%. \n",
    "The predicted admission results are seen having errors compared to actual admissions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image6-kresults.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AdaBoost Classifier: \n",
    "As shown as below, the accuracy score keeps 69% regardless of number of trees trained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image7-adascore.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests Classifier:\n",
    "The highest accuracy rate 69% is generated from training one tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image7-rfscore.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests model cannot interpret how predictors impact the classification - admitted or not, but can tell us what predictors are important. The features are ranked by importance from the model as shown as below. The order is aligned up with the predictor coefficients from Logistic Regression model. When GPA and GRE are rescaled and follow the same Gaussian distribution, GPA score is expected to have higher impact on admission decision than GRE score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image8-featurebar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion: Write up your discussion and future steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) As stated in results session and visual charts, gpa and gre scores are positively associated with the probability of being admitted but the association is not statistically significant. The odds of these two factors are affected by college rankings. So future steps could be splitting dataset by prestige and testing association levels between scores and admission for each prestige. \n",
    "2) The classifier prediction is not strong for all of applied models. It might due to a) data sample size (400 observations) is small; b) predictors are too limited just three input variables. To increase prediction power, more data points should be colleted and other related factors should be added into model to test such as study majors, genders, nationalities and other input that is required to submit in the university application process. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
